CamemBERT is a French version of the Bi-directional Encoders for Transformers (BERT) It is based on Facebook's RoBERTa model released in 2019. It is a modeltrained on 138GB of French text. It improves the state of the art for most of the tasks considered. The original code can be found here. The implementation is the same as RoberTa. Refer to the documentation for usage examples as well as the information relative to the inputs and outputs. The model was contributed by camembert and the code is available here. It was developed by Louis Martin, Benjamin Muller, Pedro Javier Ortiz Suárez, Yoann Dupont, Laurent Romary, Éric Villemonte de laClergerie, Djamé Seddah, and Benoît Sagot. For more information, visit CamemberT: a Tasty French Language Model and Camembert: a French NLP Model, or go to: http://www.camembert.com/Camembert-French-NLP-Model-2.html. The code is also available at: http: //www.camberembert.org/CAMEMBERT-France-Linguistic-Model.