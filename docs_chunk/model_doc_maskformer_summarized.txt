The MaskFormer model was proposed in Per-Pixel Classification is Not All You Need for Semantic Segmentation by Bowen Cheng, Alexander G. Schwing, Alexander Kirillov. MaskFormer addresses semantic segmentation with a mask classification paradigm instead of performing classic pixel-level classification. The model's Transformer decoder is identical to the decoder of DETR. During training, the authors found it helpful to use auxiliary losses in the decoding, especially to help the model output the correct number of objects of each class. If you want to train the model in a distributed environment across multiple nodes, then one should update the get_num_masks function inside in the MaskFormerLoss class of modeling_mask. The original code can be found here. The API hasn't been tested extensively. There may be some bugs or slight breaking changes to fix it in the future. Ifyou see something strange, file a Github Issue. The figure below illustrates the architecture of MaskFormer. Taken from the original paper. It was contributed by francesco and can be downloaded from the Github site here. It is based on a version of the paper published by the University of California, San Diego, titled "Per-Pixel classification is not all you need forSemantic Se segmentation"