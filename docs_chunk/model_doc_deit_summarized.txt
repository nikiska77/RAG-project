The DeiT model was proposed in Training data-efficient image transformers & distillation through attention by Hugo Touvron, Matthieu Cord, Matthijs Douze, Francisco Massa, AlexandreSablayrolles, Hervé Jégou. The abstract from the paper is the following:Recently, neural networks purely based on attention were shown to address image understanding tasks such as image classification. However, these visual transformers are pre-trained with hundreds of millions of images using an expensive infrastructure, thereby limiting their adoption. In this work, we produce a competitive convolution-freetransformer by training on Imagenet only. We train them on a single computer in less than 3 days. Our reference vision                transformer (86M parameters) achieves top-1 accuracy of 83.1% (single-crop evaluation) on ImageNet with no external data. More importantly, we introduce a teacher-student strategy specific to transformers. It relies on a distillationiablytoken ensuring that the student learns from the teacher through attention. We show the interest of this token-baseddistillation, especially when using a convnet as a teacher. This leads us to report results competitive with convnetsfor both Imagenets and when transferring to other tasks. We share our code and models.