This guide focuses on training large models efficiently on CPU. IPEX provides performance optimizations for CPU training with both Float32 and BFloat16. The Auto Mixed Precision for CPU backend has been enabled since PyTorch-1.10.0. The usage of B float16 is the main focus of the following sections.IPEX is optimized for CPUs with AVX-512 or above, and functionally works for CPU with only AVX2. So, it is expected to bring performance benefit for Intel CPU generations with AVZ-512. Older Intel CPUs might result in a better performance under IPEX, but not guaranteed. Check more detailed information for IPEX Auto mixed Precision. The IPEX release is following Py Torch, to install via pip: PIP install intel_extension_for_pytorch==<version_name> -f https://developer.intel.com/ipex-whl-stable-cpu.ipx-release.ipEX version: 1.13.0+.ipx version:  1.11.200+cpu. ipx release:   Â 1.12.300+ CPU.ipex version: 0.1.1+.ipEX release: 1:1.2.0!ipxversion:  0.01.0%.ipexversion: 1.:1.3.0!.ipx versions: 0:0.0, 0:1, 0.3, 1.4.0,. IPEX version : 1.1, 2, 3, 4, 5, 6, 7.