MobileNet V2 was proposed in MobileNetV2: Inverted Residuals and Linear Bottlenecks by Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, Liang-Chieh Chen. The architecture is based on an inverted residual structure where the input and output of the residual block are thin bottleneck layers. The checkpoints are named mobilenet_v2_depth_size. The smallest supported image size is 32x32. The original code and weights can be found here for the main model and here for DeepLabV3+. The model will work on images of any size. Even though the checkpoint is trained on specific size, the model will working on images. The model was contributed by matthijs. It can be used to prepare images by using [MobileNet v2ImageProcessor] or MobileNet v3 ImageProcessor. For more information, visit the MobileNetv2 website. It is open-source and can be downloaded for free from the Google Play Store and the GitHub repository. It has been described as a "mobile architecture" that improves the state of the art performance of mobile models on multiple tasks and benchmarks. It uses lightweight depthwise convolutions to filter features in the intermediate expansion layer.