The Donut model was proposed in OCR-free Document Understanding Transformer. It consists of an image Transformer encoder and an autoregressive text Transformer decoder. It is used to perform document understanding tasks such as document image classification, form understanding and visual question answering. The quickest way to get started with Donut is by checking the tutorial notebooks, which show how to use the model at inference time as well as fine-tuning on custom data. The model was contributed by nielsr, and the original code can be found at:https://www.researchgate.com/public/index.php?title=Document-understanding-transformer-donut-model. The abstract from the paper is the following:Understanding document images (e.g., invoices) is a core but challenging task since it requires complex functions such as reading text and a holistic understanding of the document. Current Visual Document Understanding (VDU) methods outsource the task of reading text to off-the-shelf Optical Character Recognition (OCR) engines and focus on the understanding task with the OCR outputs. To address these issues, in this paper, we introduce a novel O CR-free VDU model named Donut, which stands for Document understanding transformer.