The model was proposed in SpeechT5: Unified-Modal Encoder-Decoder Pre-Training for Spoken Language Processing by Junyi Ao, Rui Wang, Long Zhou, Chengyi Wang, Shuo Ren, Yu Wu, Shujie Liu, Tom Ko, Qing Li, Yu Zhang, Zhihua Wei, Yao Qian, Jinyu Li, Furu Wei. The abstract from the paper is the following:Motivated by the success of T5 (Text-To-Text Transfer Transformer) in pre-trained natural language processing models, we propose a unified-modal SpeechT 5 framework that explores the encoder-decoder pre-training for self-supervised speech/text representation learning. Extensive evaluations show the superiority of the proposed speechT5 framework on a wide variety of spoken language processing tasks, including automatic speech recognition, speech synthesis, speech translation, voice conversion, speech enhancement, and speaker identification.This model was contributed by Matthijs. The original code can be found here. The model is available for download from the Jupyter Notebook by clicking here: http://www.jupytersnotebook.com/speech-t5/SpeechT5-model.html.