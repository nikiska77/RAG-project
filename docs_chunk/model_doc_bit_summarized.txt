Big Transfer (BiT) is a simple recipe for scaling up pre-training of ResNet-like architectures (specifically, ResNetv2) The method results in significant improvements for transfer learning. BiT achieves 87.5% top-1 accuracy on ILSVRC-2012, 99.4% on CIFAR-10, and 76.3% on the 19 task Visual Task Adaptation Benchmark (VTAB) BiT performs well across a surprisingly wide range of data regimes -- from 1 example per class to 1M total examples. The original code can be found here. A list of official Hugging Face and community resources to help you get started with BiT is available here. If you're interested in submitting a resource to be included in the list, please send it to jennifer.glanfield@mailonline.co.uk. The list includes: BitForImageClassification[BitForImage classification] [BitFor image classification], BitFor image classification, BitFor classification, and BitFor captioning. The full list of resources is available at the bottom of the page. For more information, see the Hugging face website. The Hugging faces website is also available at: http://www.huggingface.com/.