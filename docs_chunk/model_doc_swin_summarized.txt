Swin Transformer was proposed in Swin Transformer: Hierarchical Vision Transformer using Shifted Windows by Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, Baining Guo. The paper presents a new vision Transformer that capably serves as a general-purpose backbone for computer vision. Its performance surpasses the previous state-of-the-art by a large margin. It is compatible with a broad range of vision tasks, including image classification (87.3 top-1 accuracy on ImageNet-1K) and denseprediction tasks such as object detection (58.7 box AP and 51.1 mask AP on COCO test-dev) and semantic segmentation (53.5 mIoU on ADE20K val). Its design and the shifted window approach also prove beneficial for all-MLP architectures. When output_hidden_states = True, it will output both hidden_states and resh. It pads the inputs supporting any input height and width (if divisible by 32). It can be used as a backbone. The original code can be found here. The Tensorflow version of this model was contributed by amyeroberts.