The PoolFormer model was proposed in MetaFormer is Actually What You Need for Vision by Sea AI Labs. Instead of designing complicated token mixer to achieve SOTA performance, the target of this work is to demonstrate the competence of transformer models largely stem from the general architecture MetaFormer. For example, on ImageNet-1K, PoolFormer achieves 82.1% top-1 accuracy, surpassing well-tuned vision transformer/MLP-like baselines DeiT-B/Res MLP-B24 by 0.3%/1.1%. The effectiveness of PoolFormer verifies our hypothesis and urges us to initiate the concept of "MetaFormer", a general architecture abstracted from transformers without specifying the token mixer. This work calls for more future research dedicated to improving MetaFormer instead of focusing on theToken mixer modules. All checkpoints of the model can be found on the hub. One can use [PoolFormerImageProcessor] to prepare images for the model. This model was contributed by heytanay. The original code can befound here. The figure below illustrates the architecture of Pool former. It comes in different models, including a simple Average Pooling layer and a more complex spatial pooling layer. The model is available for download here.