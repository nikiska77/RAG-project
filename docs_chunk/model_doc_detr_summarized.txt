The DETR model was proposed in End-to-End Object Detection with Transformers by Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander Kirillov and Sergey Zagoruyko. It greatly simplifies a lot of the complexity of models like Faster-R-CNN. It can also be extended to perform panoptic segmentation, by simply adding a mask head on top of the decoder outputs. The model is conceptually simple and does not require a specialized library, unlike many other modern detectors. The original code can be found here. The paper was published in the Journal of Computer Vision and Pattern Recognition (JCVPR) on November 6, 2013. It was published by the University of California, San Diego. It is available on the JCVPR website. The abstract is available here: http://www.jcmpr.org/blog/2013/11/07/detr-for-object-detection-with-transformers.html#storylink=cpy. The full paper can be downloaded from the JCPPR website here: Â http://jcmPR.com/2013-11-07/ Detr-For-Object-Detection-With-Transformers-JCPPR.html.