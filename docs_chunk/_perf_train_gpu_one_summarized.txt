This guide demonstrates practical techniques that you can use to increase the efficiency of your model's training. You can optimize memory utilization, speeding up the training, or both. If you have access to a machine with multiple GPUs, these approaches are still valid, plus you can leverage additional methods outlined in the multi-GPU section. The methods and tools covered in this guide can be classified based on the effect they have on the training process: Method/tool: Improves training speed; Optimizes memory utilization; Batch size choice. Data throughput/training time: Maximizing the throughput (samples/second) leads to lower training cost. Model performance: Maximize the model performance by maximizing the number of samples/second that can be trained at a time. Model anatomy: Understand the Model training anatomy conceptual guide first to understand how GPU is utilized during training. The Model performance section: Maximise theModel performance by increasing data throughput/ training time; Maximize model performance with a large batch size; Maximizing model performance using a largebatch size; Optimizing the Model Performance section: Optimize theModel Performance by Maximizing Data Throughput/Training Time (MTP/ Training Time) and Maximizing Model Performance by Increasing MTP/Training time (TTP/ training Time (TSP/ Training time)