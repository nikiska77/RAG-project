The VITS model was proposed in Conditional Variational Autoencoder with Adversarial Learning for End-to-End Text-to -Speech by Jaehyeon Kim, Jungil Kong, Juhee Son. The model also includes a stochastic duration predictor, which allows the model to synthesise speech with different rhythms from the same input text. It is a conditional variational autoencoding (VAE) comprised of a posterior encoder, decoder, and conditional prior. A set of spectrogram-based acoustic features are predicted by the flow-based module, which is formed of a Transformer-based text encoder and multiple coupling layers. The spectrogram is decoded using a stack of transposed convolutional layers, much in the same style as the HiFi-GAN vocoder. The VITS method adopts variational inference augmented with normalizing flows and an adversarial training process, which improves the expressive power of the model. It also uses a combination of losses derived from variational lower bound and adversarial learning. The method is based on the K-means-K-m-s method, which was developed in the 1990s by the University of California, San Diego.