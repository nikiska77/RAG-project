Pop2Piano is an encoder-decoder Transformer model based on T5. It is the first model to directly generate a piano cover from pop audio. It uses time, velocity, note and'special' token types. The token ids are then decoded to their equivalent MIDI file. To use it, you will need to install the Transformers library, as well as the following third party modules: pretty-midi==0.9.2.9 essent essent. The original code can be found here. The model was contributed by Susnato Dhar, Jongho Choi and Kyogu Lee. The abstract from the paper is the following: Piano covers of pop music are enjoyed by many people. However, the task of automatically generating piano covers is still understudied. This is partly due to the lack of synchronized{Pop, Piano Cover} data pairs, which made it challenging to apply the latest data-intensive deep learning-based methods. To leverage the power of the data-driven approach, we make a large amount of synchronized and synchronized {Pop,. Piano Cover}. data using an automated Pipeline. We show that Pop1Piano, trained with our dataset, is capable of producing plausible piano covers.