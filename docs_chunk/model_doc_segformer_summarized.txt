The SegFormer model was proposed in SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Enze Xie, Wenhai Wang, Zhiding Yu, Anima Anandkumar, Jose M. Alvarez, Ping Luo. The model consists of a hierarchical Transformer encoder and a lightweight all-MLP decode head. It has been shown to achieve great results on image segmentation benchmarks such as ADE20K and Cityscapes. For example, SegFormer-B4 achieves 50.3% mIoU on ADe20K with 64M parameters, being 5x smaller and 2.2% better than the previous best method. Our best model, Seg former-B5, achieves 84.0% miU on Cityscape validation set and shows excellent zero-shot robustness on City Scapes-C. The figure below illustrates the architecture of SegFormer. Taken from the original paper. The TensorFlow version of the model was contributed by sayakpaul. The original code can be found here. The paper is also referred to as Mix Transformer or MiT, which is the model used in this article. It was written by Xie, Wang, Yu, Alvarez, Alvarez and Luo.