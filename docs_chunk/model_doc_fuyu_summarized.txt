The Fuyu model was created by ADEPT, and authored by Rohan Bavishi, Erich Elsen, Curtis Hawthorne, Maxwell Nye, Augustus Odena, Arushi Somani, Sağnak Taşırlar. It is a decoder-only multimodal model based on the classic transformers architecture, with query and key normalization. With 8 billion parameters and licensed under CC-BY-NC, FuyU-8B is notable for its ability to handle both text and images, its impressive context size of 16K, and its overall performance. The checkpoints uploaded on the hub use torch_dtype = 'float16' which will be used by the AutoModel API to cast the checkpoints from torch. float32 to torch.float16.Finetuning the model in float16 is not recommended and known to produce nan, as such the model should be fine-tuned in b float16. To convert the model, you need to clone the original repository using git clone https://github.com/persimmon-ai-labs/adept-inference, then get the checkpoints:git clone http://www.fuyu-8b-studies.org/.