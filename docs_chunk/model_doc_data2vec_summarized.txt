The Data2Vec model was proposed in data2vec: A General Framework for Self-supervised Learning in Speech, Vision and Language. The core idea is to predict latent representations of the full input data based on a masked view of the input in a selfdistillation setup. The model was contributed by edugp and patrickvonplaten. The original code (for NLP and Speech) can be found here and the original code for vision can be seen here. Models and code are available at www.github.com/pytorch/fairseq/tree/master/examples/data2vec. Back to Mail Online home. Back To the page you came from. The abstract from the paper is the following:. The general idea of self-super supervised learning is identical across modalities. But the actual algorithms and. objectives differ widely because they were developed with a single modality in mind. The. algorithm and the objectives differ because the. algorithms and objectives were developed for one modality - text, audio and images. The framework uses the same learning method for either speech, NLP or computer vision. The code for the model is available on www. GitHub.com and the source code is available for TensorFlow.