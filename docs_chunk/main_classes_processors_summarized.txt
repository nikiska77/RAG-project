Transformers library includes 10 processors for the following tasks: MRPC, MNLI, MN LI (mismatched), CoLA, SST2, STSB,QQP, QNLI, RTE and WNLI. All processors follow the same architecture which is that of the data.processors.DataProcessor. The processor returns a list of objects that can be fed to the model. These objects include tokenizers (for the text modality), image processors (for vision) and feature extractors (for audio) The library was released with the paper GLUE: Amulti-task benchmark and analysis platform for natural language understanding. It was released together with the. paper GLue: A multi-task benchmarks and analysis platforms for natural. language understanding, which was published in June 2013. The library is free and open-source, and can be downloaded from the source code of the Transformers library at: http://www.transformers.org/transformers/Transformers-Library.html. It is also available as a binary download from the download page at:http:// www.Transformers.com/TransformERS-Library/Transformer-Library-2.0/transformer-2-1/transformation-3.0.sh.