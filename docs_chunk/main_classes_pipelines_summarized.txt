Pipelines are objects that abstract most of the complex code from the library. They offer a simple API dedicated to several tasks, including Named Entity Recognition, Masked Language Modeling, Sentiment Analysis, Feature Extraction and Question Answering. There are two categories of pipeline abstractions to be aware of: The [pipeline] which is the most powerful object encapsulating all other pipelines. The pipeline abstraction is a wrapper around all the other available pipelines and is instantiated as any other pipeline. To iterate over full datasets it is recommended to use a dataset directly. This means you don't need to allocate the whole dataset at once, nor do you need to do batching yourself. See thetask summary for examples of use. The pipelines are a great and easy way to use models for inference. They are available for audio, computer vision, natural language processing, and multimodal tasks. They can also be used to call a pipeline on many items, you can call it with a list. For example: pipeline("text-classification")pipe( ["This restaurant is awesome", "This restaurants is awful"])pipe('text- classification', {'label': 'POSITIVE','score': 0.9998743534088135,'score: 0.9996669292449951}.