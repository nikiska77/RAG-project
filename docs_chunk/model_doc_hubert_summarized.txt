Hubert was proposed in HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units by Wei-Ning Hsu, Benjamin Bolte, Yao-Hung Hubert Tsai, Kushal Lakhotia, RuslanSalakhutdinov, Abdelrahman Mohamed. The model accepts a float array corresponding to the raw waveform of the speech signal. It was fine-tuned using connectionist temporal classification (CTC) so the model output has to be decoded using [Wav2Vec2CTCTokenizer]. The model either matches or improves upon the state-of-the-art wav2vec 2.0 performance on the Librispeech (960h) and Libri-light (60,000h) benchmarks with 10min, 1h, 10h, 100h, and 960h fine- Tuning subsets. Using a 1B parameter model, HuberT shows up to 19% and 13% relative WERreduction on the more challenging dev-other and test-other evaluation subsets, according to the authors. The paper was published in the open-source journal, Caffeine and Cognition. It can be downloaded for free from the Mac.