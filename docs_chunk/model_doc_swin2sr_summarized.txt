Swin2R improves the SwinIR model by incorporating Swin Transformer v2 layers. This mitigates issues such as training instability, resolution gaps between pre-training and fine-tuning, and hunger on data. Swin2SR is a top-5 solution at the "AIM 2022 Challenge on Super-Resolution of Compressed Image and Video" The original code can be found here. A demo Space for image super-resolution with SwinSR can befound here. The SwinV2 Transformer for Compressed image Super-resolution and Restoration was proposed by Marcos V. Conde, Ui-Jin Choi, Maxime Burchi, Radu Timofte in a paper published in September 2013. The paper was published in the journal Computer Vision and Pattern Recognition (CPRR) and was written by Marcos Conde and Ui Jin Choi. It was published by the University of California, San Diego. The abstract is available at: http://www.cprr.org/blog/2013/09/07/swin-v2-transformer-for-compressed-image-super-resolutions-and-restoration.html. For more information on the CPRR project, visit: http:/www.crr.com/news/2013-09/06/swin-v-3-transformation-from-convolution- neural-netrails-to-convolution-neurons-in-the-cloud.