The Audio Spectrogram Transformer applies a Vision Transformer to audio, by turning audio into an image (spectrogram) The model obtains state-of-the-art results for audio classification. The AST needs a low learning rate (the authors use a 10 times smaller learning rate compared to their CNN model proposed in thePSLA paper) and converges quickly. It uses the AudioSetmean and std by default. You can check ast/src/get_norm_stats.py to see how the authors compute the stats for a downstream dataset. It's recommended to take care of the input normalization (to make sure the input has mean of 0 andstd of 0.5). [ASTFeatureExtractor] takes care of this. The model was contributed by nielsr. The original code can be found here. A list of official Hugging Face and community resources is available here. For more information on Hugging Faces, visit Hugging faces.org. For the latest version of this article, see Huggingfaces.org and HuggingFace.org for more details on how to use the Hugging face tool in your own work. It is also available as a free download from the Google Play store. The Huggingface tool can be downloaded from the App Store for free.