DiT was proposed in DiT: Self-supervised Pre-training for Document Image Transformer by Junlong Li, Yiheng Xu, Tengchao Lv, Lei Cui, Cha Zhang, Furu Wei. It applies the self-super supervised objective of BEiT (BERT pre-training of Image Transformers) to 42 million document images. It can be used for state-of-the-art results on tasks including document image classification, document layout analysis, as well as table detection. One can directly use the weights of DiT with the AutoModel API by importing AutoModel.from_pretrained("Microsoft/dit-base") into the model. Note that this won't include the PubLayNet dataset, which is a collection of more than 360,000 document images constructed by automatically parsing PubMed XML files. The model was contributed by nielsr. The original code can be found here. The abstract from the paper is the following:*Image Transformer has recently achieved significant progress for natural image understanding. We leverage DiT as the backbone network in a variety of vision-based Document AI tasks. We propose DiT, a self- supervised pre-trained Document image Transformer model using large-scale unlabeled text images.