Wav2Vec2Phoneme is a speech model that accepts a float array corresponding to the raw waveform of the speech signal. It can be fine-tuned on multiple language at once and decode unseen languages in a single forward pass. The model was trained using connectionist temporal classification (CTC) so the model output has to be decoded using CTCokenizer. In order to transform the phonemes to a sequence of words one should make use of a dictionary and language model. The original code can be found here. For API reference, check out Wav2 Vec2's documentation page except for Wav1Vec1 and Wav3Vec3. For more information on the Wav 2Vec 2 model, see the WAV2VEC2 documentation page or see the documentation page for WAV1VEC3 and WAV3VEC1. For a more detailed look at how the model works, please visit the WV2Vac 2.0 documentation page. For the full version of this article, please go to: http://www.huggingface.co/models?other=phoneme-recognition.html. The full version can be downloaded from the following link:http://huggesface. co.uk/models/wav2vac-2-0/v1vac2-2.html#v1.0.