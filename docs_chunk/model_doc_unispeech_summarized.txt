UniSpeech is a speech model that accepts a float array corresponding to the raw waveform of the speech signal. The model can be fine-tuned using connectionist temporal classification (CTC) so the model output has to be decoded using [Wav2Vec2CTCTokenizer]. The model was contributed by patrickvonplaten. The Authors' code can be found here. The UniSpeech model was proposed in UniSpech: Unified Speech Representation Learning with Labeled and Unlabeled Data by Chengyi Wang, Yu Wu, Yao Qian, Kenichi Kumatani, Shujie Liu, Furu Wei, Michael                Zeng, Xuedong Huang. The abstract from the paper is the following:. In this paper, we propose a unified pre-training approach called UniSpeach to learn speech representations with both. unlabeled and labeled data, in which supervised phonetic CTC learning and phonetically-aware contrastive. learning are conducted in a multi-task learning manner. The resultant representations can capture information more correlated with phonetic structures and improve the generalization across languages and domains. We.evaluate the effectiveness of Uni Speech for cross-lingual representation learning on public CommonVoice corpus.