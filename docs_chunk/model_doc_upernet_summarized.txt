UPerNet is a framework for semantic segmentation. It can be used with any vision backbone, like ConvNeXt or Swin. The original code is based on OpenMMLab's mmsegmentation here. The trained networks are further applied to discover visual knowledge in natural scenes. The model was contributed by nielsr and the code was written by Tete Xiao, Yingcheng Liu, Bolei Zhou, Yuning Jiang, Jian Sun. The UPerNet model was proposed in Unified Perceptual Parsing for Scene Understanding. The abstract from the paper is the following:Humans recognize the visual world at multiple levels. We effortlessly categorize scenes and detect objects inside, while also identifying the textures and surfaces of the objects along with their different compositional parts. In this paper, we study a new task called Unified PerCEPTual Parsed. The task requires the machine vision systems to recognize as many visual concepts as possible from a given image. A multi-task framework called UPer net and a training strategy are developed to learn from heterogeneous image annotations. We benchmark our framework on Unified perceptual parsing and show that it is able to effectively segment a wide range of concepts from images. The training strategy is called UperNetForSemanticSegmentation.