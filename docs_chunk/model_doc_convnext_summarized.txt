ConvNeXT is a pure convolutional model (ConvNet) inspired by the design of Vision Transformers. It claims to outperform them in terms of accuracy and scalability. The model was proposed in A ConvNet for the 2020s by Zhuang Liu, Hanzi Mao, Chao-Yuan Wu, Christoph Feichtenhofer, Trevor Darrell, Saining Xie. The original code can be found here. A list of official Hugging Face and community resources to help you get started with ConvNeXT can be seen here. The code for the TensorFlow version of the model was contributed by ariG23498, sayakpaul (equal contribution), and ariR23498 (equal contributions). The original paper is available on the arXiv.org/17061/convnext-1.0.0-alpha. The full paper can be downloaded from the arxiv site here: http://www.arxiv.com/v1/17071/vnext.0/alpha/convNeXT-1-alpha-vnex.0-.0.1.html#vneXt is a family of pure ConvNet models built from standard ConvNet modules. Constructed entirely from standardconvolutional modules, ConvNeXts compete favorably with Transformers. They achieve 87.8% ImageNet top-1 accuracy.