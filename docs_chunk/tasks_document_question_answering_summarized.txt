 layoutLMv2 solves the document question-answering task. The problem is treated as extractive question answering: given the context, extract which piece of information answers the question. The context comes from the output of an OCR engine, here it is Google's Tesseract. We use a small sample of preprocessed DocVQA that you can find on Hub. If you'd like to use the full dataset, you can register and download it on the homepage. Check out how to load files into a Dataset to help you with the process. We encourage you to share your model with the community. Log in to your Hugging Face account to upload it to the Hub. We hope to see your model in the next version of this guide. Back to Mail Online home. back to the page where you came from. READ: How to build a layout model with Google's OCR software. Back To the page you come from. Click here for the next part of the guide, where we show you how to build the layout model using Googleâ€™s OCR technology. Click to go to the next page to see the next step, where you can download the model and test it on your computer. The next step is to load the data into a dataset. Click the next button to try it out.