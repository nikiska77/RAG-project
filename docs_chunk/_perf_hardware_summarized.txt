The hardware you use to run model training and inference can have a big effect on performance. For a deep dive into GPUs make sure to check out Tim Dettmer's excellent blog post. Let's have a look at some practical advice for GPU setups.Custom hardware for training is a good way to get the most out of your data. For training bigger models you have essentially three options:bigger GPUs                more GPUs                 more CPU and NVMe (offloaded to by DeepSpeed-Infinity) More CPU andNVMe. More memory. More storage. More RAM. More data storage. A lot of data storage! More memory! More storage! A lot more RAM! More power. More power! More RAM! A LOT more storage! And more data! More data! A huge amount of data! But how much do you really need to train a model? A lot! A big, huge, huge amount. A huge, big, big amount! A very large, large amount! But a very small, small amount? A very small amount?! A tiny bit? A few hundredths of a milliwatt? That's it! That's all you need! A small amount of power! A few thousand watts! A couple of hundred watts! That will do the job. But it's not enough.