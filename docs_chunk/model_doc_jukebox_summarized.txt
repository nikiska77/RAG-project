Jukebox is a generative music model which can produce minute long samples that can be conditioned on artist, genres and lyrics. The model is very slow, and takes 8h to generate a minute long audio using the 5 priors. The original code can be found here. This model only supports inference. It requires a crazy amount of memory to train. Feel free to open a PR and add what's missing to have a full integration with the hugging face traineer! The model was contributed by Arthur Zucker and Prafulla Dhariwal. The abstract from the paper is the following:We introduce Jukebox, a model that generates music with singing in the raw audio domain. We tackle the long context of raw audio using a multiscale VQ-VAE to compress it to discrete codes, and modeling those using autoregressive Transformers. We show that the combined model at scale can generate high-fidelity and diverse songs with coherence up to multiple minutes. We can condition on artist and genre to steer the musical and vocal style, and on unaligned lyrics to make the singing more controllable. We are releasing thousands of non cherry-picked samples, along with model weights and code. The models can be downloaded from: http://www.jukebox.org/.