The Time Series Transformer model is a vanilla encoder-decoder Transformer for time series forecasting. It is a so-called probabilistic forecasting model, not a point forecasting model. The model doesn't directly output values, but learns a distribution, from which one can sample. It consists of 2 blocks: an encoder, which takes a context_length of time series values as input (called past_values), and a decoder, who predicts a prediction_length. During training, one needs to provide pairs of (past_values and future_values) to the model. These can be the following:past_time_features: temporal features which the model will add to future_ values.future_time-features: Time features that are stacked together as a vector. static_categorical_ features: features that serve as "positional encodings" for the Transformer decoder. This model was contributed by kashif. Use this model to help you with your own time-series forecasting. For more information, visit the TimeSeriesTransformerModel page or the Time SeriesTransformerForPrediction page. The TimeSeries Transformer Model can be downloaded from the GitHub repository. It can also be downloaded as a zip file from the repository.